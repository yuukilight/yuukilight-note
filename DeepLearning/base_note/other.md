## Promt tunning
"Prompt tuning" 是一种轻量级的参数高效微调方法，它不需要修改整个大模型的权重，而是通过学习**少量的可训练向量（prompt embeddings）**来引导模型产生你想要的输出。它主要应用于像 GPT-3、T5、BERT 这样的预训练语言模型。

### 📌 基本概念
- 目标：让预训练模型在特定任务上表现更好，而不微调全部参数。

- 方法：插入一组可学习的嵌入向量（prompt tokens），前缀在输入前，让模型根据这些向量引导其行为。

### 优势：

- 可训练参数数量少（例如只训练几十个向量）

- 训练快、计算资源少

- 在多任务环境中灵活性强