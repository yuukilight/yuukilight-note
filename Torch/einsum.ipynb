{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einsum (Einsum is all you need)\n",
    "\n",
    "- **Free Indices:** Are the indices specified in the outpus\n",
    "- **Summation Indices:** All other indices. Those that appear in the input argument\n",
    "  but Not in output specification.\n",
    "\n",
    "  ex: 矩阵乘法运算中 $A_{i k} \\cdot B_{k  j} = Result_{ij}$， i 和 j 就是 Free Indices, k 是 Summation Indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_x = torch.rand(3, 5)\n",
    "mat_y = torch.rand(5, 2)\n",
    "mat_c = torch.empty((3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(mat_x.shape[0]):\n",
    "    for j in range(mat_y.shape[1]):\n",
    "        tmp_total = 0\n",
    "        for k in range(mat_x.shape[1]):\n",
    "            tmp_total += mat_x[i][k] * mat_y[k][j]\n",
    "\n",
    "        mat_c[i][j] = tmp_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.9031, 0.7166],\n",
       "        [0.8968, 0.6699],\n",
       "        [1.3841, 0.8715]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_t1 = mat_x @ mat_y\n",
    "mat_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True],\n",
       "        [True, True],\n",
       "        [True, True]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_c == mat_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_einsum = torch.einsum('ik, kj -> ij', mat_x, mat_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.9031, 0.7166],\n",
       "        [0.8968, 0.6699],\n",
       "        [1.3841, 0.8715]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_einsum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上例中 i, j 是 Free Indices,\n",
    "k 是 Summation Indices.\n",
    "在 k 循环中求和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(5)\n",
    "b = torch.rand(3)\n",
    "c = torch.empty((5, 3))\n",
    "\n",
    "outer = torch.einsum('i, j -> ij', a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8842, 0.6382, 0.2734, 0.6178, 0.3061])\n",
      "tensor([0.6580, 0.6709, 0.2253])\n",
      "tensor([[0.5818, 0.5932, 0.1992],\n",
      "        [0.4199, 0.4282, 0.1438],\n",
      "        [0.1799, 0.1834, 0.0616],\n",
      "        [0.4065, 0.4145, 0.1392],\n",
      "        [0.2014, 0.2054, 0.0690]])\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(b)\n",
    "print(outer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(a.shape[0]):\n",
    "    for j in range(b.shape[0]):\n",
    "        c[i][j] = a[i] * b[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5818, 0.5932, 0.1992],\n",
       "        [0.4199, 0.4282, 0.1438],\n",
       "        [0.1799, 0.1834, 0.0616],\n",
       "        [0.4065, 0.4145, 0.1392],\n",
       "        [0.2014, 0.2054, 0.0690]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('i ->', x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自己的一点小理解，就是循环每个索引。\n",
    "\n",
    "先循环结果中的索引(i, j)，再循环结果中没有的索引(k)。\n",
    "\n",
    "对于结果中没有的索引，计算后再相加进行累积，然后填入到结果中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RULES:\n",
    "1. Repeating letters in different inputs means \n",
    "   those values will be multiplied and those products will be the output.\n",
    "2. Omitting a letter means that axis will be summed.\n",
    "3. We can return the unsummed axes in any order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3718, 0.5213, 0.8097],\n",
       "        [0.1012, 0.9702, 0.6299]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.rand((2, 3))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "tensor([[0.5497, 0.7491],\n",
      "        [0.9246, 0.6787],\n",
      "        [0.5731, 0.8049]])\n"
     ]
    }
   ],
   "source": [
    "# Permutation of Tensor\n",
    "\n",
    "len_i = x.shape[0]\n",
    "len_j = x.shape[1]\n",
    "result = torch.empty((len_j, len_i))\n",
    "for i in range(len_i):\n",
    "    for j in range(len_j):\n",
    "        result[j][i] = x[i][j]\n",
    "        \n",
    "t = torch.einsum(\"ij -> ji\", x)\n",
    "\n",
    "print(torch.all(result == t))\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "tensor(4.2801)\n"
     ]
    }
   ],
   "source": [
    "# Summation\n",
    "len_i = x.shape[0]\n",
    "len_j = x.shape[1]\n",
    "result = torch.empty((1))\n",
    "\n",
    "tmp_sum = 0\n",
    "for i in range(len_i):\n",
    "    for j in range(len_j):\n",
    "        tmp_sum += x[i][j]\n",
    "\n",
    "result = tmp_sum\n",
    "\n",
    "t = torch.einsum(\"ij ->\", x)\n",
    "print(t == result)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(False)\n",
      "tensor([0.4730, 1.4914, 1.4396])\n"
     ]
    }
   ],
   "source": [
    "# Column Sum\n",
    "# column sum 即把元素按列求和， 如果有 m 列，每一列都求和得到 (1,m)。 (n, m) -> (1, m)\n",
    "# 即有多少列，就能得到几个数，每一列的数都被求和\n",
    "len_i = x.shape[0]\n",
    "len_j = x.shape[1]\n",
    "result = torch.empty((len_j))\n",
    "\n",
    "\n",
    "for i in range(len_i):\n",
    "    for j in range(len_j):\n",
    "        result[j] += x[i][j]\n",
    "\n",
    "t = torch.einsum(\"ij -> j\", x)\n",
    "print(torch.all(t == result))\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "tensor([2.0475, 2.2326])\n"
     ]
    }
   ],
   "source": [
    "# Row Sum\n",
    "len_i = x.shape[0]\n",
    "len_j = x.shape[1]\n",
    "result = torch.empty((len_i))\n",
    "\n",
    "for i in range(len_i):\n",
    "    tmp_total = 0\n",
    "    for j in range(len_j):\n",
    "        tmp_total += x[i][j]\n",
    "    result[i] = tmp_total\n",
    "\n",
    "t = torch.einsum(\"ij -> i\", x)\n",
    "print(torch.all(t == result))\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "tensor([[1.3543],\n",
      "        [1.5067]])\n"
     ]
    }
   ],
   "source": [
    "# Matrix-Vector Multiplication\n",
    "v = torch.rand((1, 3))\n",
    "\n",
    "len_i = x.shape[0]\n",
    "len_j = x.shape[1]\n",
    "len_k = v.shape[0]\n",
    "result = torch.empty((len_i, len_k))\n",
    "\n",
    "for i in range(len_i):\n",
    "    for k in range(len_k):\n",
    "        tmp_total = 0\n",
    "        for j in range(len_j):\n",
    "            tmp_total += x[i][j] * v[k][j]\n",
    "        result[i][k] = tmp_total\n",
    "\n",
    "t = torch.einsum(\"ij, kj -> ik\", x, v)  # (2, 3) @ (3, 1)\n",
    "print(torch.all(t == result))\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "tensor([[1.4857, 1.5006],\n",
      "        [1.5006, 1.6696]])\n"
     ]
    }
   ],
   "source": [
    "# Matrix-Matrix Multiplication\n",
    "len_i = x.shape[0]\n",
    "len_j = x.shape[1]\n",
    "len_k = x.shape[0]\n",
    "result = torch.empty((len_i, len_k))\n",
    "\n",
    "for i in range(len_i):\n",
    "    for k in range(len_k):\n",
    "        tmp_total = 0\n",
    "        for j in range(len_j):\n",
    "            tmp_total += x[i][j] * x[k][j]\n",
    "        result[i][k] = tmp_total\n",
    "\n",
    "t = torch.einsum(\"ij, kj -> ik\", x, x)  # (2, 3) @ (3, 2)\n",
    "print(torch.all(t == result))\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4857)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dot product first row with first row of matrix\n",
    "torch.einsum(\"i, i -> \", x[0], x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.1552)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dot product with matrix\n",
    "torch.einsum(\"ij, ij ->\",x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hadamard Product (element-wise multiplication)\n",
    "len_i = x.shape[0]\n",
    "len_j = x.shape[1]\n",
    "result = torch.empty((len_i, len_j))\n",
    "\n",
    "for i in range(len_i):\n",
    "    for j in range(len_j):\n",
    "        result[i][j] = x[i][j] * x[i][j]\n",
    "\n",
    "t = torch.einsum(\"ij, ij -> ij\", x, x)\n",
    "torch.all(t == result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True],\n",
       "        [True, True, True, True, True],\n",
       "        [True, True, True, True, True]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outer Product\n",
    "a = torch.rand((3))\n",
    "b = torch.rand((5))\n",
    "\n",
    "len_i = a.shape[0]\n",
    "len_j = b.shape[0]\n",
    "result = torch.empty((len_i, len_j))\n",
    "\n",
    "for i in range(len_i):\n",
    "    for j in range(len_j):\n",
    "        result[i][j] = a[i] * b[j]\n",
    "\n",
    "t = torch.einsum(\"i, j -> ij\", a, b)\n",
    "# torch.all(t, result)\n",
    "t == result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.2354, 1.4121, 1.6984],\n",
       "         [2.4894, 1.5692, 1.6881]],\n",
       "\n",
       "        [[1.2697, 1.6723, 0.9452],\n",
       "         [0.7643, 1.5241, 0.7664]],\n",
       "\n",
       "        [[1.2094, 0.4053, 0.4002],\n",
       "         [1.1668, 0.5641, 0.7423]]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch Matrix Multiplication\n",
    "a = torch.rand((3 , 2, 5))\n",
    "b = torch.rand((3, 5, 3))\n",
    "torch.einsum(\"ijk, ikl -> ijl\", a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix Diagonal\n",
    "len_i = x.shape[0]\n",
    "result = torch.empty((len_i))\n",
    "\n",
    "for i in range(len_i):\n",
    "    result[i] = x[i][i]\n",
    "\n",
    "t = torch.einsum(\"ii -> i\", x)\n",
    "t == result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_i = x.shape[0]\n",
    "len_j = x.shape[1]\n",
    "result = torch.empty((len_i))\n",
    "\n",
    "for i in range(len_i):\n",
    "    tmp_total = 0\n",
    "    for j in range(len_j):\n",
    "        tmp_total += x[i][j]\n",
    "    result[i] = tmp_total\n",
    "\n",
    "t = torch.einsum(\"ij -> i\", x)\n",
    "t == result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix Trace\n",
    "len_i = x.shape[0]\n",
    "result = torch.empty((1))\n",
    "\n",
    "for i in range(len_i):\n",
    "    result += x[i][i]\n",
    "\n",
    "t = torch.einsum(\"ii->\", x)\n",
    "t == result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vector attention test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn = torch.rand((4, 10, 3, 32))\n",
    "value = torch.rand((4, 10, 3, 32))\n",
    "\n",
    "batch_size, num_points, k_num, feature = attn.shape\n",
    "\n",
    "# result = torch.empty((batch_size, num_points, feature))\n",
    "result = torch.zeros((batch_size, num_points, feature))\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for n in range(num_points):\n",
    "        for k in range(k_num):\n",
    "            for f in range(feature):\n",
    "                result[b, n, f] += attn[b, n, k, f] * value[b, n, k, f]\n",
    "\n",
    "\n",
    "t = torch.einsum('bnkf,bnkf->bnf', attn, value)\n",
    "torch.all(t == result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 32])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pointcept",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
