{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decorator\n",
    "本质上，decorator就是一个返回函数的高阶函数。所以，我们要定义一个能打印日志的decorator，可以定义如下：\n",
    "\n",
    "如下代码，log 本质上是一个 接受一个函数作为参数，并返回一个函数的高阶函数。\n",
    "\n",
    "使用 log 装饰 now 后再执行相当于：\n",
    "now = log(now)\n",
    "now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: now()\n",
      "2025-12-25\n"
     ]
    }
   ],
   "source": [
    "def log(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        print(f'Calling: {func.__name__}()')\n",
    "        return func(*args, **kwargs)\n",
    "    return wrapper\n",
    "\n",
    "@log\n",
    "def now():\n",
    "    print('2025-12-25')\n",
    "\n",
    "now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也就是说 now 函数被重新指向后 再执行。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importlib\n",
    "\n",
    "用来动态导入配置文件\n",
    "\n",
    "因为根据任务不同，需要导入的配置文件可能不同。使用 importlib 方法可以根据任务的类型来动态的选择需要导入的配置文件\n",
    "\n",
    "```python\n",
    "import importlib\n",
    "\n",
    "\n",
    "task_module = import.import_module(self.task_mapping[config.task_type])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## contextlib\n",
    "\n",
    "python 中读写文件后要正确的关闭。\n",
    "一个方法是使用 try...finally\n",
    "```python\n",
    "try:\n",
    "    f = open('/path/to/file', 'r')\n",
    "    f.read()\n",
    "finally:\n",
    "    if f:\n",
    "        f.close()\n",
    "```\n",
    "python 提供了 with 语句供我们方便的使用文件资源，并自动关闭，上面的代码可以简化为\n",
    "```python\n",
    "with open('/path/to/file', 'r') as f:\n",
    "    f.read()\n",
    "```\n",
    "\n",
    "实际上除了 open 函数返回的 fp(file pointer) 对象可以使用 with 语句。\n",
    "只要实现了上下文管理就可以使用 with 语句。\n",
    "上下文管理是通过 ```__enter__``` 和 ```__excit__``` 两个方法实现的。\n",
    "例如下面的类，实现了这两个方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin\n",
      "Query info about Bob...\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "class Query(object):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def __enter__(self):\n",
    "        print('Begin')\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_value, traceback):\n",
    "        if exc_type:\n",
    "            print('Error')\n",
    "        else:\n",
    "            print('End')\n",
    "    \n",
    "    def query(self):\n",
    "        print('Query info about %s...' % self.name)\n",
    "\n",
    "with Query('Bob') as q:\n",
    "    q.query()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "编写 ```__enter__``` 和 ```__exit__``` 仍然很繁琐，因此Python的标准库contextlib提供了更简单的写法，上面的代码可以改写如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin\n",
      "Query info about Bob...\n",
      "End\n",
      "Query info about Bob...\n"
     ]
    }
   ],
   "source": [
    "from contextlib import contextmanager\n",
    "\n",
    "class Query(object):\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def query(self):\n",
    "        print('Query info about %s...' % self.name)\n",
    "\n",
    "@contextmanager\n",
    "def create_query(name):\n",
    "    print('Begin')\n",
    "    q = Query(name)\n",
    "    yield q\n",
    "    print('End')\n",
    "\n",
    "# @contextmanager这个decorator接受一个generator，用yield语句把with ... as var把变量输出出去，然后，with语句就可以正常地工作了：\n",
    "\n",
    "with create_query('Bob') as q:\n",
    "    q.query()\n",
    "\n",
    "# 这里 q 在退出 with 后没有释放资源，如果要释放资源，可以在 yield 后或者 __exit__ 中释放资源\n",
    "q.query()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "很多时候，我们希望在某段代码执行前后自动执行特定代码，也可以用@contextmanager实现。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1\n",
      "Hello\n",
      "world\n",
      "/h1\n"
     ]
    }
   ],
   "source": [
    "@contextmanager\n",
    "def tag(name):\n",
    "    print(name)\n",
    "    yield\n",
    "    print('/' + name)\n",
    "\n",
    "with tag('h1'):\n",
    "    print('Hello')\n",
    "    print('world')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的代码首先执行 yield 之前的语句\n",
    "\n",
    "再执行with 内所有的语句\n",
    "\n",
    "最后执行 yield 后的代码\n",
    "\n",
    "简单来说 @contextmanager让我们通过编写generator来简化上下文管理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果一个对象没有实现上下文，我们就不能把它用于with语句。这个时候，可以用closing()来把该对象变为上下文对象。例如，用with语句使用urlopen()：\n",
    "```python\n",
    "from contextlib import closing\n",
    "from urllib.request import urlopen\n",
    "\n",
    "with closing(urlopen('https://www.python.org')) as page:\n",
    "    for line in page:\n",
    "        print(line)\n",
    "```\n",
    "\n",
    "closing也是一个经过@contextmanager装饰的generator，这个generator编写起来其实非常简单：\n",
    "\n",
    "```python\n",
    "@contextmanager\n",
    "def closing(thing):\n",
    "    try:\n",
    "        yield thing\n",
    "    finally:\n",
    "        thing.close()\n",
    "```\n",
    "\n",
    "它的作用就是把任意对象变为上下文对象，并支持with语句。\n",
    "\n",
    "@contextlib还有一些其他decorator，便于我们编写更简洁的代码。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial function\n",
    "\n",
    "通过设定参数的默认值，可以降低函数调用的难度。而偏函数也可以做到这一点。举例如下：\n",
    "\n",
    "int()函数可以把字符串转换为整数，当仅传入字符串时，int()函数默认按十进制转换："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12345"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int('12345')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但int()函数还提供额外的base参数，默认值为10。如果传入base参数，就可以做N进制的转换：\n",
    "\n",
    "(base = 8, 表示的是输入的参数是 8 进制， 下面的例子中 '12345' 是 8 进制或者 16进制)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int('12345', base=8) = 5349\n",
      "int('12345', 16) = 74565\n"
     ]
    }
   ],
   "source": [
    "print(f\"int('12345', base=8) = {int('12345', base=8)}\")\n",
    "\n",
    "print(f\"int('12345', 16) = {int('12345', 16)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设要转换大量的二进制字符串，每次都传入int(x, base=2)非常麻烦，于是，我们想到，可以定义一个int2()的函数，默认把base=2传进去："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int2('1000000') = 64\n",
      "int2('1010101') = 85\n"
     ]
    }
   ],
   "source": [
    "def int2(x, base=2):\n",
    "    return int(x, base)\n",
    "\n",
    "print(f\"int2('1000000') = {int2('1000000')}\")\n",
    "\n",
    "print(f\"int2('1010101') = {int2('1010101')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```functools.partial``` 就是帮助我们创建一个偏函数的，不需要我们自己定义```int2()```，可以直接使用下面的代码创建一个新的函数int2："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int2('1000000') = 64\n",
      "int2('1010101') = 85\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "int2 = functools.partial(int, base=2)\n",
    "\n",
    "print(f\"int2('1000000') = {int2('1000000')}\")\n",
    "\n",
    "print(f\"int2('1010101') = {int2('1010101')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以，简单总结functools.partial的作用就是，把一个函数的某些参数给固定住（也就是设置默认值），返回一个新的函数，调用这个新函数会更简单。\n",
    "\n",
    "注意到上面的新的int2函数，仅仅是把base参数重新设定默认值为2，但也可以在函数调用时传入其他值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int2('1000000', base=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，创建偏函数时，实际上可以接收函数对象、*args和**kw这3个参数，当传入：\n",
    "```python\n",
    "int2 = functools.partial(int, base=2)\n",
    "```\n",
    "实际上固定了int()函数的关键字参数base，也就是：\n",
    "int2('10010')\n",
    "相当于：\n",
    "```python\n",
    "kw = { 'base': 2 }\n",
    "int('10010', **kw)\n",
    "```\n",
    "\n",
    "当传入:\n",
    "```python\n",
    "max2 = functools.partial(max, 10)\n",
    "```\n",
    "\n",
    "实际上会把10作为*args的一部分自动加到左边，也就是：\n",
    "```python\n",
    "max2(5, 6, 7)\n",
    "```\n",
    "相当于\n",
    "```python\n",
    "args = (10, 5, 6, 7)\n",
    "max(*args)\n",
    "```\n",
    "结果为 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 网络编程\n",
    "\n",
    "IP协议负责把数据从一台计算机通过网络发送到另一台计算机。\n",
    "\n",
    "IP地址实际上是一个32位整数（称为IPv4），以字符串表示的IP地址如192.168.0.1实际上是把32位整数按8位分组后的数字表示，目的是便于阅读。\n",
    "\n",
    "IPv6地址实际上是一个128位整数，它是目前使用的IPv4的升级版，以字符串表示类似于2001:0db8:85a3:0042:1000:8a2e:0370:7334。\n",
    "\n",
    "TCP协议则是建立在IP协议之上的。TCP协议负责在两台计算机之间建立可靠连接，保证数据包按顺序到达。\n",
    "\n",
    "一个TCP报文除了包含要传输的数据外，还包含源IP地址和目标IP地址，源端口和目标端口。\n",
    "\n",
    "端口有什么作用？在两台计算机通信时，只发IP地址是不够的，因为同一台计算机上跑着多个网络程序。一个TCP报文来了之后，到底是交给浏览器还是QQ，就需要端口号来区分。每个网络程序都向操作系统申请唯一的端口号，这样，两个进程在两台计算机之间建立网络连接就需要各自的IP地址和各自的端口号。\n",
    "\n",
    "一个进程也可能同时与多个计算机建立链接，因此它会申请很多端口。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Socket\n",
    "\n",
    "Socket是网络编程的一个抽象概念。通常我们用一个Socket表示“打开了一个网络链接”，而打开一个Socket需要知道目标计算机的IP地址和端口号，再指定协议类型即可。\n",
    "\n",
    "大多数连接都是可靠的TCP连接。创建TCP连接时，主动发起连接的叫客户端，被动响应连接的叫服务器。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 子进程\n",
    "### Popen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filelock\n",
    "\n",
    "首先要明白为什么需要加锁，举个例子：n 个读者到图书馆查阅 1 本书籍。但是这本书同一时间只能借给一个人。我们需要如何协调？\n",
    "\n",
    "Python filelock库是一个用于文件锁定的工具，可以帮助开发者在多线程或多进程环境中管理文件的并发访问，避免数据竞争和冲突。\n",
    "\n",
    "- 支持基于文件的锁定机制\n",
    "- 提供了上下文管理器来自动管理锁的获取和释放\n",
    "- 支持超时机制，防止死锁情况发生\n",
    "- 可以管理多个文件的锁定状态"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 获取文件锁\n",
    "\n",
    "在这个示例中，创建了一个文件锁lock，并使用上下文管理器with lock来获取文件锁，然后在锁定范围内执行操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World!\n",
      "Hello, World!\n",
      "Hello, World!\n",
      "Hello, World!\n",
      "Hello, World!\n",
      "Hello, World!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from filelock import FileLock\n",
    "\n",
    "# 创建文件锁\n",
    "lock = FileLock(\"data.txt.lock\")\n",
    "\n",
    "# 获取文件锁\n",
    "with lock:\n",
    "    # 在锁定范围内执行操作\n",
    "    with open(\"data.txt\", \"a\") as file:\n",
    "        file.write(\"Hello, World!\\n\")\n",
    "\n",
    "with lock:\n",
    "    with open(\"data.txt\", \"r\") as f:  # 打开文件\n",
    "        data = f.read()  # 读取文件\n",
    "        print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World!\n",
      "Hello, World!\n",
      "Hello, World!\n",
      "Hello, World!\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 超时机制\n",
    "\n",
    "在这个示例中，创建了一个超时为5秒的文件锁lock，并使用lock.acquire(timeout=2)来尝试获取文件锁，如果超时则会抛出Timeout异常。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filelock import Timeout, FileLock\n",
    "\n",
    "# create the lock, and set a 5 second timeout\n",
    "lock = FileLock(\"data.txt.lock\", timeout=5)\n",
    "\n",
    "try:\n",
    "    # try to acquire the lock\n",
    "    with lock.acquire(timeout=2):\n",
    "        # execute operation in the locked scope\n",
    "        with open(\"data.txt\", \"a\") as file:\n",
    "            file.write(\"Hello, World!\\n\")\n",
    "except Timeout:\n",
    "    print(\"acquire lock timeout!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 文件锁的释放"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filelock import FileLock\n",
    " \n",
    "# 创建文件锁\n",
    "lock = FileLock(\"data.txt.lock\")\n",
    " \n",
    "# 获取文件锁\n",
    "with lock:\n",
    "    # 在锁定范围内执行操作\n",
    "    with open(\"data.txt\", \"a\") as file:\n",
    "        file.write(\"Hello, World!\\n\")\n",
    "    \n",
    "    # 手动释放文件锁\n",
    "    lock.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Runner\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from mmengine.model import BaseModel\n",
    "from mmengine.evaluator import BaseMetric\n",
    "from mmengine.registry import MODELS, DATASETS, METRICS\n",
    "\n",
    "\n",
    "@MODELS.register_module()\n",
    "class MyAwesomeModel(BaseModel):\n",
    "    def __init__(self, layers=4, activation='relu') -> None:\n",
    "        super().__init__()\n",
    "        if activation == 'relu':\n",
    "            act_type = nn.ReLU\n",
    "        elif activation == 'silu':\n",
    "            act_type = nn.SiLU\n",
    "        elif activation == 'none':\n",
    "            act_type = nn.Identity\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        sequence = [nn.Linear(2, 64), act_type()]\n",
    "        for _ in range(layers-1):\n",
    "            sequence.extend([nn.Linear(64, 64), act_type()])\n",
    "        self.mlp = nn.Sequential(*sequence)\n",
    "        self.classifier = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, data, labels, mode):\n",
    "        x = self.mlp(data)\n",
    "        x = self.classifier(x)\n",
    "        if mode == 'tensor':\n",
    "            return x\n",
    "        elif mode == 'predict':\n",
    "            return F.softmax(x, dim=1), labels\n",
    "        elif mode == 'loss':\n",
    "            return {'loss': F.cross_entropy(x, labels)}\n",
    "\n",
    "\n",
    "@DATASETS.register_module()\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, is_train, size):\n",
    "        self.is_train = is_train\n",
    "        if self.is_train:\n",
    "            torch.manual_seed(0)\n",
    "            self.labels = torch.randint(0, 2, (size,))\n",
    "        else:\n",
    "            torch.manual_seed(3407)\n",
    "            self.labels = torch.randint(0, 2, (size,))\n",
    "        r = 3 * (self.labels+1) + torch.randn(self.labels.shape)\n",
    "        theta = torch.rand(self.labels.shape) * 2 * torch.pi\n",
    "        self.data = torch.vstack([r*torch.cos(theta), r*torch.sin(theta)]).T\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index], self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "@METRICS.register_module()\n",
    "class Accuracy(BaseMetric):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def process(self, data_batch, data_samples):\n",
    "        score, gt = data_samples\n",
    "        self.results.append({\n",
    "            'batch_size': len(gt),\n",
    "            'correct': (score.argmax(dim=1) == gt).sum().cpu(),\n",
    "        })\n",
    "\n",
    "    def compute_metrics(self, results):\n",
    "        total_correct = sum(r['correct'] for r in results)\n",
    "        total_size = sum(r['batch_size'] for r in results)\n",
    "        return dict(accuracy=100*total_correct/total_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, default_collate\n",
    "from torch.optim import Adam\n",
    "from mmengine.runner import Runner\n",
    "\n",
    "\n",
    "runner = Runner(\n",
    "    # 你的模型\n",
    "    model=MyAwesomeModel(\n",
    "        layers=2,\n",
    "        activation='relu'),\n",
    "    # 模型检查点、日志等都将存储在工作路径中\n",
    "    work_dir='exp/my_awesome_model',\n",
    "\n",
    "    # 训练所用数据\n",
    "    train_dataloader=DataLoader(\n",
    "        dataset=MyDataset(\n",
    "            is_train=True,\n",
    "            size=10000),\n",
    "        shuffle=True,\n",
    "        collate_fn=default_collate,\n",
    "        batch_size=64,\n",
    "        pin_memory=True,\n",
    "        num_workers=2),\n",
    "    # 训练相关配置\n",
    "    train_cfg=dict(\n",
    "        by_epoch=True,   # 根据 epoch 计数而非 iteration\n",
    "        max_epochs=10,\n",
    "        val_begin=2,     # 从第 2 个 epoch 开始验证\n",
    "        val_interval=1), # 每隔 1 个 epoch 进行一次验证\n",
    "\n",
    "    # 优化器封装，MMEngine 中的新概念，提供更丰富的优化选择。\n",
    "    # 通常使用默认即可，可缺省。有特殊需求可查阅文档更换，如\n",
    "    # 'AmpOptimWrapper' 开启混合精度训练\n",
    "    optim_wrapper=dict(\n",
    "        optimizer=dict(\n",
    "            type=Adam,\n",
    "            lr=0.001)),\n",
    "    # 参数调度器，用于在训练中调整学习率/动量等参数\n",
    "    param_scheduler=dict(\n",
    "        type='MultiStepLR',\n",
    "        by_epoch=True,\n",
    "        milestones=[4, 8],\n",
    "        gamma=0.1),\n",
    "\n",
    "    # 验证所用数据\n",
    "    val_dataloader=DataLoader(\n",
    "        dataset=MyDataset(\n",
    "            is_train=False,\n",
    "            size=1000),\n",
    "        shuffle=False,\n",
    "        collate_fn=default_collate,\n",
    "        batch_size=1000,\n",
    "        pin_memory=True,\n",
    "        num_workers=2),\n",
    "    # 验证相关配置，通常为空即可\n",
    "    val_cfg=dict(),\n",
    "    # 验证指标与验证器封装，可自由实现与配置\n",
    "    val_evaluator=dict(type=Accuracy),\n",
    "\n",
    "    # 以下为其他进阶配置，无特殊需要时尽量缺省\n",
    "    # 钩子属于进阶用法，如无特殊需要，尽量缺省\n",
    "    default_hooks=dict(\n",
    "        # 最常用的默认钩子，可修改保存 checkpoint 的间隔\n",
    "        checkpoint=dict(type='CheckpointHook', interval=1)),\n",
    "\n",
    "    # `luancher` 与 `env_cfg` 共同构成分布式训练环境配置\n",
    "    launcher='none',\n",
    "    env_cfg=dict(\n",
    "        cudnn_benchmark=False,   # 是否使用 cudnn_benchmark\n",
    "        backend='nccl',   # 分布式通信后端\n",
    "        mp_cfg=dict(mp_start_method='fork')),  # 多进程设置\n",
    "    log_level='INFO',\n",
    "\n",
    "    # 加载权重的路径 (None 表示不加载)\n",
    "    load_from=None,\n",
    "    # 从加载的权重文件中恢复训练\n",
    "    resume=False\n",
    ")\n",
    "\n",
    "# 开始训练你的模型吧\n",
    "runner.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmdet3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
